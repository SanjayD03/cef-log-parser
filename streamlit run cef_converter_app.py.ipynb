{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff72e442-7d4f-475f-bea8-d6ec1194f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09fe741c-d990-44d1-b120-c7bcb0b14f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#App Title and File Upload\n",
    "# Title\n",
    "st.title(\"CEF to CSV Converter - Anaplan Log Parser\")\n",
    "\n",
    "# File uploader\n",
    "file = st.file_uploader(\"Upload .cef File\", type=[\"cef\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be73cd7-5a4a-4e18-bc68-cc14dace4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing function\n",
    "def process_cef(file):\n",
    "    try:\n",
    "        # Load data\n",
    "        df = pd.read_csv(file, sep='|', header=None)\n",
    "\n",
    "        # Rename columns\n",
    "        df = df.rename(columns={0: 'Time stamp', 5: 'actions', 6: 6})\n",
    "\n",
    "        # Extract user ID\n",
    "        user_id = []\n",
    "        for i in range(df.shape[0]):\n",
    "            check_list = str(df[6][i]).split(' ')\n",
    "            for j in check_list:\n",
    "                if \"userId\" in j:\n",
    "                    user_id.append(j[7:])\n",
    "                    break\n",
    "            else:\n",
    "                user_id.append(\"NO USER ID\")\n",
    "        df['User ID'] = user_id\n",
    "\n",
    "        # Extract workspace ID\n",
    "        workspace_id = []\n",
    "        for i in range(df.shape[0]):\n",
    "            check_list = str(df[6][i]).split(' ')\n",
    "            found = False\n",
    "            for j in check_list:\n",
    "                if \"workspaceId\" in j:\n",
    "                    parts = j.split(',')\n",
    "                    for k in parts:\n",
    "                        x = k.find(\"workspaceId\")\n",
    "                        if x >= 0:\n",
    "                            workspace_id.append(k[x+14:].replace('}', '').strip('\"'))\n",
    "                            found = True\n",
    "                            break\n",
    "                    if found:\n",
    "                        break\n",
    "            if not found:\n",
    "                workspace_id.append(f\"NO WORKSPACE ID FOUND at {i}\")\n",
    "        df['Workspace ID'] = workspace_id\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        df.drop(columns=[1, 2, 3, 4, 6], inplace=True, errors='ignore')\n",
    "\n",
    "        # Clean timestamp\n",
    "        df['Time stamp'] = df['Time stamp'].astype(str).apply(lambda x: x[:-9] if 'T' in x and len(x) > 8 else x)\n",
    "        df['Date'] = df['Time stamp'].apply(lambda x: x.split('T')[0] if 'T' in x else '')\n",
    "        df['Time'] = df['Time stamp'].apply(lambda x: x.split('T')[1] if 'T' in x else '')\n",
    "\n",
    "        # Filter for Butterfly workspace\n",
    "        butterfly_id = '8a81b09b664b166b016654daf2185553'\n",
    "        filtered_df = df[df['Workspace ID'] == butterfly_id].reset_index(drop=True)\n",
    "        filtered_df['flag'] = True\n",
    "\n",
    "        # Extract timestamp from file name\n",
    "        base_filename = os.path.basename(file.name)\n",
    "        match = re.search(r\"user_activity.*\", base_filename)\n",
    "        suffix = match.group(0).replace(\".cef\", \"\") if match else \"output\"\n",
    "\n",
    "        # Output file name\n",
    "        output_filename = f\"Butterfly_CM_RM_PM - {suffix}.csv\"\n",
    "        filtered_df.to_csv(output_filename, index=False)\n",
    "\n",
    "        return df, filtered_df, output_filename, butterfly_id\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error processing file: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80248167-73de-4056-9641-cf550ddc1d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UI Logic and Output\n",
    "if file is not None:\n",
    "    st.info(\"Processing file...\")\n",
    "    df_all, df_filtered, out_file, workspace_id_used = process_cef(file)\n",
    "\n",
    "    if df_filtered is not None:\n",
    "        st.success(\"‚úÖ File successfully processed and saved.\")\n",
    "        st.subheader(\"üîç Preview of Filtered Data\")\n",
    "        st.dataframe(df_filtered.head(10))\n",
    "\n",
    "        with open(out_file, \"rb\") as f:\n",
    "            st.download_button(\"üì• Download CSV\", f, file_name=out_file, mime='text/csv')\n",
    "\n",
    "        # Summary stats\n",
    "        st.subheader(\"üìä Summary\")\n",
    "        st.write(f\"**Filtered Workspace ID**: `{workspace_id_used}`\")\n",
    "        st.write(f\"**Total Records in Uploaded File**: `{df_all.shape[0]}`\")\n",
    "        st.write(f\"**Records after Filtering**: `{df_filtered.shape[0]}`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fccdb6e-d591-4fcc-948c-3598fde219c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ad813-1480-4bda-8b24-f349f160a857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8a8d4-1b4c-4056-b520-23e2654d7608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
